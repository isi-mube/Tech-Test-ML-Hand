{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7f2c04-0f8b-4839-9913-fa741ca5303a",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #00BFFF;\">00 |</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57054209-f10c-44bb-8743-d6ba2fc53362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Basic libraries\n",
    "import os # file managment\n",
    "import matplotlib.pyplot as plt #  plots and visualizations\n",
    "import numpy as np # numerical python, image array manipulation\n",
    "\n",
    "# üõ†Ô∏è Tools\n",
    "import warnings # who likes warnings?\n",
    "import shutil # high-level file operations\n",
    "import random # to generate random samples\n",
    "\n",
    "# üåê Computer Vision\n",
    "import cv2 # the most basic library to read images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # real-time data augmentation\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img, load_img # saving augmented Data\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow import keras # deep learning and neural networks\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfed5c5-ae22-447c-a606-6ebaf48ffd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Settings\n",
    "warnings.filterwarnings('ignore') # ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3d2c4c-5719-4655-b98a-50cd158b316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb97ae-a133-4b0e-a9b4-97d78b66a9b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #00BFFF;\">01 | Data Extraction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd07524-3312-4439-bd1a-b9fe09fb65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('C:\\\\Users\\\\apisi\\\\01. IronData\\\\01. GitHub\\\\03. Projects\\\\07_hands_on_it', '01_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a4229-0207-4e43-b325-17052f66f2c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Preparing Test folder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff35839d-9e1a-4da5-b09c-c5f44cca9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(data_path, \"03_test\")\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "# original and no_bg directories for test\n",
    "os.makedirs(os.path.join(test_dir, \"original\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"mask\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d9191-f260-4cab-9c36-d823db319c06",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Preparing Train and Validation folder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274cf52b-7caf-414f-ac23-481d18a947bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_path, \"01_train\")\n",
    "val_dir = os.path.join(data_path, \"02_validation\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "# original and no_bg directories for train and validation\n",
    "os.makedirs(os.path.join(train_dir, \"original\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, \"mask\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, \"original\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, \"mask\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653a754-d8c0-43fc-b838-77b812ae67f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #00BFFF;\">02 | Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b620b-e184-4c5d-a49f-203665ed8007",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #00BFFF;\">Improving is an iterative process...</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb4bf6-b5c7-4d8e-a86e-a39c5360c470",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Preparing Test folder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837767f8-0903-4ad2-913e-9de94989ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(data_path, \"03_test\")\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "# original and no_bg directories for test\n",
    "os.makedirs(os.path.join(test_dir, \"original\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"mask\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f67031-0338-41c1-916b-403cede75642",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Preparing Train and Validation folder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa234d0-9de5-417f-854a-3ff88c47c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_path, \"01_train\")\n",
    "val_dir = os.path.join(data_path, \"02_validation\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "# original and no_bg directories for train and validation\n",
    "os.makedirs(os.path.join(train_dir, \"original\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, \"mask\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, \"original\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, \"mask\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af21199c-deab-4d99-96fe-19c41a43e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that we can fine-tune later on\n",
    "img_height = 480\n",
    "img_width = 272\n",
    "image_size = (img_height, img_width)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b0f3c-4b93-43bd-9b77-c8d84e722010",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Normalization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0230ce2c-2783-4426-986b-084b8cc3c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_mask_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058b91b-22e1-4336-8ebe-b9d88cec9fc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Debugging ImageDataGenerator</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96b073-cb89-42e5-b2b3-b425e4e706e7",
   "metadata": {},
   "source": [
    "(wasn't detecting the images, they need to be in subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02bfd10-fe90-4497-9408-94079fdd48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original_dir = os.path.join(train_dir, \"original\")\n",
    "train_mask_dir = os.path.join(train_dir, \"mask\")\n",
    "\n",
    "val_original_dir = os.path.join(val_dir, \"original\")\n",
    "val_mask_dir = os.path.join(val_dir, \"mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4335a6c-b5fe-44a2-9b0e-720ebfa67a7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Train and Validation Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9b7117-e79c-47a0-9c0e-1e8c5fbe2203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 249 images belonging to 1 classes.\n",
      "Found 249 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_gen = train_image_datagen.flow_from_directory(\n",
    "    train_original_dir,\n",
    "    class_mode=None,\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_mask_gen = train_mask_datagen.flow_from_directory(\n",
    "    train_mask_dir,\n",
    "    class_mode=None,\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799977a1-df77-40fa-914c-d47e79b3d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = zip(train_image_gen, train_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f79e37be-2c25-4c96-b494-c61c72668665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 images belonging to 1 classes.\n",
      "Found 7 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "val_image_gen = val_image_datagen.flow_from_directory(\n",
    "    val_original_dir,\n",
    "    class_mode=None,\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_mask_gen = val_mask_datagen.flow_from_directory(\n",
    "    val_mask_dir,\n",
    "    class_mode=None,\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff288575-1d96-4a18-b7bc-de3296eef391",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = zip(val_image_gen, val_mask_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6accb2-18d6-4189-a4f1-97414e12d7ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: #008080;\">Compiling the Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f70aa0fe-dbaa-490b-842e-7511eebf30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_resnet_model(input_shape=(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9117d1d-dd34-4904-bc2e-d86b6de18738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=0.01),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f8fbbec-cdb0-42a3-ba3f-309404c58cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_image_gen)\n",
    "validation_steps = len(val_image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef86f495-fea8-41c6-8027-0d64c487eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = os.path.join(data_path, \"04_epochs\", \"save_at_transfer_{epoch}.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9edba-ab58-49c7-8806-2a8e9d6a4cee",
   "metadata": {},
   "source": [
    "epochs = 30\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(checkpoints),\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    train_ds, \n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e15313-0c44-4afb-9df3-ad753b3fceb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #00BFFF;\">06 | Evaluating the Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef8786b4-be65-4dbc-a885-9671a8fc5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  path to best epoch\n",
    "checkpoint_path = os.path.join(data_path, \"04_epochs\", \"save_at_transfer_30.keras\")\n",
    "\n",
    "# load the model\n",
    "loaded_model = load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "821cd0a5-39a6-4375-9fc6-7fbfb0fcdbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original_dir = os.path.join(test_dir, \"original\")\n",
    "test_mask_dir = os.path.join(test_dir, \"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d21e0-5a95-4bb9-bef4-c39203122ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_datagen = ImageDataGenerator()\n",
    "test_mask_datagen = ImageDataGenerator()\n",
    "\n",
    "test_image_gen = test_image_datagen.flow_from_directory(\n",
    "    test_original_dir,\n",
    "    class_mode=None,\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_mask_gen = test_mask_datagen.flow_from_directory(\n",
    "    test_mask_dir,\n",
    "    class_mode=None,\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be9fbb-36b0-4500-b4a7-6d225da9b8bc",
   "metadata": {},
   "source": [
    "test_ds = zip(test_image_gen, test_mask_gen)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = loaded_model.evaluate(test_ds, steps=len(test_image_gen))\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68448a69-9447-450a-8799-36eea13433c9",
   "metadata": {},
   "source": [
    "images, masks = next(test_ds)\n",
    "\n",
    "# predict masks using the model\n",
    "predicted_masks = loaded_model.predict(images)\n",
    "\n",
    "# plotting original, true masks, predicted masks, and segmented images\n",
    "for i in range(min(5, batch_size)):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Display original image\n",
    "    plt.subplot(1, 4, 1)\n",
    "    image_to_display = images[i].astype(np.uint8)\n",
    "    plt.imshow(image_to_display)\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    # Display true mask\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(masks[i].squeeze(), cmap='gray')\n",
    "    plt.title('True Mask')\n",
    "\n",
    "    # Display predicted mask\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(predicted_masks[i].squeeze(), cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    \n",
    "    # Display segmented image\n",
    "    plt.subplot(1, 4, 4)\n",
    "    segmented_image = (images[i] * predicted_masks[i].squeeze()[:, :, np.newaxis]).astype(np.uint8)\n",
    "    plt.imshow(segmented_image)\n",
    "    plt.title('Segmented Image')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067a2c7-b83d-45a7-b2ab-a87bd0f95a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
